# ==========================================
# 第一阶段：构建前端
# ==========================================
FROM node:20-slim AS frontend-builder
WORKDIR /app/frontend
COPY frontend/package*.json ./
RUN npm install
COPY frontend/ ./
RUN npm run build

# ==========================================
# 第二阶段：最终运行环境 (支持 GPU)
# ==========================================
# 使用 NVIDIA CUDA 运行时作为基础镜像
FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

# 设置工作目录
WORKDIR /app

# 设置环境变量，避免交互式安装提示
ENV DEBIAN_FRONTEND=noninteractive

# 安装 Python 3.11 以及必要的系统依赖
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3-pip \
    python3.11-dev \
    curl \
    git \
    ffmpeg \
    libsndfile1 \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 将 python3.11 设置为默认 python
RUN ln -sf /usr/bin/python3.11 /usr/bin/python \
    && ln -sf /usr/bin/pip3 /usr/bin/pip

# 安装 uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /uv/bin/
ENV PATH="/uv/bin:${PATH}"

# 复制后端依赖文件
COPY backend/requirements.txt ./

# 1. 安装基础依赖
RUN uv pip install --no-cache -r requirements.txt --system

# 2. 安装本地模型运行所需的深度学习依赖 (针对 CUDA 12.1)
RUN uv pip install --no-cache torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --system

# 3. 安装 Qwen3-TTS 核心库
# 注意：如果 pypi 版本未发布，可能需要从 git 安装，这里先尝试 pypi
RUN uv pip install --no-cache qwen-tts --system

# 4. 可选：安装 FlashAttention 2 以优化性能 (构建时间较长，如不需要可注释掉)
# RUN uv pip install --no-cache flash-attn --no-build-isolation --system

# 复制后端代码
COPY backend/ ./

# 确保必要的目录存在
RUN mkdir -p previews data uploads samples

# 从第一阶段复制构建好的前端静态文件
COPY --from=frontend-builder /app/frontend/dist /app/static

# 设置本地运行相关的环境变量
ENV QWEN3_TTS_ENV=local
ENV PORT=8000
# 允许下载模型时的超时设置
ENV HF_HUB_ENABLE_HF_TRANSFER=0

# 设置 Hugging Face 缓存目录，方便外部挂载持久化
ENV HF_HOME=/app/models_cache

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
